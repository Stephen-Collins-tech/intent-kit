{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98711a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc5b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intent_kit import IntentGraphBuilder, handler, llm_classifier\n",
    "\n",
    "# LLM configuration (remove if not using LLM-powered features)\n",
    "LLM_CONFIG = {\n",
    "    \"provider\": \"openai\",\n",
    "    \"api_key\": OPENAI_API_KEY,\n",
    "    \"model\": \"gpt-4.1-mini\",\n",
    "}\n",
    "\n",
    "\n",
    "def _calculate_handler(operation: str, a: float, b: float) -> str:\n",
    "    \"\"\"Handle calculation with proper operator mapping.\"\"\"\n",
    "    operation_map = {\n",
    "        \"plus\": \"+\",\n",
    "        \"add\": \"+\",\n",
    "        \"minus\": \"-\",\n",
    "        \"subtract\": \"-\",\n",
    "        \"times\": \"*\",\n",
    "        \"multiply\": \"*\",\n",
    "        \"multiplied\": \"*\",\n",
    "        \"divided\": \"/\",\n",
    "        \"divide\": \"/\",\n",
    "        \"over\": \"/\",\n",
    "    }\n",
    "    math_op = operation_map.get(operation.lower(), operation)\n",
    "    try:\n",
    "        result = eval(f\"{a} {math_op} {b}\")\n",
    "        return f\"{a} {operation} {b} = {result}\"\n",
    "    except (SyntaxError, ZeroDivisionError) as e:\n",
    "        return f\"Error: Cannot calculate {a} {operation} {b} - {str(e)}\"\n",
    "\n",
    "\n",
    "def create_intent_graph():\n",
    "    \"\"\"Create and configure the intent graph.\"\"\"\n",
    "    handlers = [\n",
    "        handler(\n",
    "            name=\"greet\",\n",
    "            description=\"Greet the user\",\n",
    "            handler_func=lambda name, **kwargs: f\"Hello {name}!\",\n",
    "            param_schema={\"name\": str},\n",
    "            llm_config=LLM_CONFIG,\n",
    "        ),\n",
    "        handler(\n",
    "            name=\"calculate\",\n",
    "            description=\"Perform a calculation\",\n",
    "            handler_func=lambda operation, a, b, **kwargs: _calculate_handler(\n",
    "                operation, a, b\n",
    "            ),\n",
    "            param_schema={\"operation\": str, \"a\": float, \"b\": float},\n",
    "            llm_config=LLM_CONFIG,\n",
    "        ),\n",
    "        handler(\n",
    "            name=\"weather\",\n",
    "            description=\"Get weather information\",\n",
    "            handler_func=lambda location, **kwargs: f\"Weather in {location}: 72°F, Sunny (simulated)\",\n",
    "            param_schema={\"location\": str},\n",
    "            llm_config=LLM_CONFIG,\n",
    "        ),\n",
    "        handler(\n",
    "            name=\"help\",\n",
    "            description=\"Get help\",\n",
    "            handler_func=lambda **kwargs: \"I can help with greetings, calculations, and weather!\",\n",
    "            param_schema={},\n",
    "            llm_config=LLM_CONFIG,\n",
    "        ),\n",
    "    ]\n",
    "    classifier = llm_classifier(\n",
    "        name=\"root\",\n",
    "        children=handlers,\n",
    "        llm_config=LLM_CONFIG,\n",
    "        description=\"Main intent classifier\",\n",
    "    )\n",
    "    return IntentGraphBuilder().root(classifier).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab17590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO]\u001b[0m [intent_kit.graph.intent_graph] Added root node: root\n",
      "\u001b[32m[INFO]\u001b[0m [intent_kit.graph.intent_graph] Validating graph structure...\n",
      "\u001b[34m[DEBUG]\u001b[0m [intent_kit.graph.validation] Validating node types...\n",
      "\u001b[32m[INFO]\u001b[0m [intent_kit.graph.validation] Node type validation passed ✓\n",
      "\u001b[34m[DEBUG]\u001b[0m [intent_kit.graph.validation] Validating splitter-to-classifier routing constraints...\n",
      "\u001b[32m[INFO]\u001b[0m [intent_kit.graph.validation] Splitter routing validation passed ✓\n",
      "\u001b[34m[DEBUG]\u001b[0m [intent_kit.graph.validation] Validating graph structure...\n",
      "\u001b[34m[DEBUG]\u001b[0m [intent_kit.graph.validation] Validating splitter-to-classifier routing constraints...\n",
      "\u001b[32m[INFO]\u001b[0m [intent_kit.graph.validation] Splitter routing validation passed ✓\n",
      "\u001b[32m[INFO]\u001b[0m [intent_kit.graph.validation] Graph validation complete: 5 total nodes, routing valid: True, cycles: False\n",
      "\u001b[32m[INFO]\u001b[0m [intent_kit.graph.intent_graph] Graph validation completed successfully\n",
      "\u001b[32m[INFO]\u001b[0m [intent_kit.graph.intent_graph] Graph validation passed after adding root node\n",
      "\n",
      "Input: Hello, my name is Alice\n",
      "\u001b[34m[DEBUG]\u001b[0m [root] Classifier at 'root' routed input to 'greet'.\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor config: {'provider': 'openai', 'api_key': '***OBFUSCATED***', 'model': 'gpt-4.1-mini'}\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor prompt: You are a parameter extractor. Given a user input, extract the required parameters.\n",
      "\n",
      "User Input: Hello, my name is Alice\n",
      "\n",
      "Required Parameters:\n",
      "- name: str\n",
      "\n",
      "\n",
      "\n",
      "Instructions:\n",
      "- Extract the required parameters from the user input\n",
      "- Consider the available context information to help with extraction\n",
      "- Return each parameter on a new line in the format: \"param_name: value\"\n",
      "- If a parameter is not found, use a reasonable default or empty string\n",
      "- Be specific and accurate in your extraction\n",
      "\n",
      "Extracted Parameters:\n",
      "\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor extracted: {'name': 'Alice'}\n",
      "Intent: intent_graph\n",
      "Output: Hello Alice!\n",
      "\n",
      "Input: What's 15 plus 7?\n",
      "\u001b[34m[DEBUG]\u001b[0m [root] Classifier at 'root' routed input to 'calculate'.\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor config: {'provider': 'openai', 'api_key': '***OBFUSCATED***', 'model': 'gpt-4.1-mini'}\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor prompt: You are a parameter extractor. Given a user input, extract the required parameters.\n",
      "\n",
      "User Input: What's 15 plus 7?\n",
      "\n",
      "Required Parameters:\n",
      "- operation: str\n",
      "- a: float\n",
      "- b: float\n",
      "\n",
      "\n",
      "\n",
      "Instructions:\n",
      "- Extract the required parameters from the user input\n",
      "- Consider the available context information to help with extraction\n",
      "- Return each parameter on a new line in the format: \"param_name: value\"\n",
      "- If a parameter is not found, use a reasonable default or empty string\n",
      "- Be specific and accurate in your extraction\n",
      "\n",
      "Extracted Parameters:\n",
      "\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor extracted: {'operation': 'plus', 'a': '15', 'b': '7'}\n",
      "Intent: intent_graph\n",
      "Output: 15.0 plus 7.0 = 22.0\n",
      "\n",
      "Input: Weather in San Francisco\n",
      "\u001b[34m[DEBUG]\u001b[0m [root] Classifier at 'root' routed input to 'weather'.\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor config: {'provider': 'openai', 'api_key': '***OBFUSCATED***', 'model': 'gpt-4.1-mini'}\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor prompt: You are a parameter extractor. Given a user input, extract the required parameters.\n",
      "\n",
      "User Input: Weather in San Francisco\n",
      "\n",
      "Required Parameters:\n",
      "- location: str\n",
      "\n",
      "\n",
      "\n",
      "Instructions:\n",
      "- Extract the required parameters from the user input\n",
      "- Consider the available context information to help with extraction\n",
      "- Return each parameter on a new line in the format: \"param_name: value\"\n",
      "- If a parameter is not found, use a reasonable default or empty string\n",
      "- Be specific and accurate in your extraction\n",
      "\n",
      "Extracted Parameters:\n",
      "\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor extracted: {'location': 'San Francisco'}\n",
      "Intent: intent_graph\n",
      "Output: Weather in San Francisco: 72°F, Sunny (simulated)\n",
      "\n",
      "Input: Help me\n",
      "\u001b[34m[DEBUG]\u001b[0m [root] Classifier at 'root' routed input to 'help'.\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor config: {'provider': 'openai', 'api_key': '***OBFUSCATED***', 'model': 'gpt-4.1-mini'}\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor prompt: You are a parameter extractor. Given a user input, extract the required parameters.\n",
      "\n",
      "User Input: Help me\n",
      "\n",
      "Required Parameters:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Instructions:\n",
      "- Extract the required parameters from the user input\n",
      "- Consider the available context information to help with extraction\n",
      "- Return each parameter on a new line in the format: \"param_name: value\"\n",
      "- If a parameter is not found, use a reasonable default or empty string\n",
      "- Be specific and accurate in your extraction\n",
      "\n",
      "Extracted Parameters:\n",
      "\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor extracted: {}\n",
      "Intent: intent_graph\n",
      "Output: I can help with greetings, calculations, and weather!\n",
      "\n",
      "Input: Multiply 8 and 3\n",
      "\u001b[34m[DEBUG]\u001b[0m [root] Classifier at 'root' routed input to 'calculate'.\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor config: {'provider': 'openai', 'api_key': '***OBFUSCATED***', 'model': 'gpt-4.1-mini'}\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor prompt: You are a parameter extractor. Given a user input, extract the required parameters.\n",
      "\n",
      "User Input: Multiply 8 and 3\n",
      "\n",
      "Required Parameters:\n",
      "- operation: str\n",
      "- a: float\n",
      "- b: float\n",
      "\n",
      "\n",
      "\n",
      "Instructions:\n",
      "- Extract the required parameters from the user input\n",
      "- Consider the available context information to help with extraction\n",
      "- Return each parameter on a new line in the format: \"param_name: value\"\n",
      "- If a parameter is not found, use a reasonable default or empty string\n",
      "- Be specific and accurate in your extraction\n",
      "\n",
      "Extracted Parameters:\n",
      "\n",
      "\u001b[34m[DEBUG]\u001b[0m [llm_classifier] LLM arg extractor extracted: {'operation': 'multiply', 'a': '8', 'b': '3'}\n",
      "Intent: intent_graph\n",
      "Output: 8.0 multiply 3.0 = 24.0\n"
     ]
    }
   ],
   "source": [
    "# Test the graph\n",
    "from intent_kit.context import IntentContext\n",
    "\n",
    "graph = create_intent_graph()\n",
    "context = IntentContext(session_id=\"simple_demo\")\n",
    "\n",
    "test_inputs = [\n",
    "    \"Hello, my name is Alice\",\n",
    "    \"What's 15 plus 7?\",\n",
    "    \"Weather in San Francisco\",\n",
    "    \"Help me\",\n",
    "    \"Multiply 8 and 3\",\n",
    "]\n",
    "\n",
    "for user_input in test_inputs:\n",
    "    print(f\"\\nInput: {user_input}\")\n",
    "    result = graph.route(user_input, context=context)\n",
    "    if result.success:\n",
    "        print(f\"Intent: {result.node_name}\")\n",
    "        print(f\"Output: {result.output}\")\n",
    "    else:\n",
    "        print(f\"Error: {result.error}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
